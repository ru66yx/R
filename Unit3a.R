quality <- read.csv("quality.csv", header = TRUE)
head(quality)
summary(quality)
str(quality)
table (quality$PoorCare)
98/131
install.packages("caTools")
library(caTools)
set.seed(88)
split = sample.split(quality$PoorCare, SplitRatio = .75)
split
qualityTest = subset(quality, split == FALSE)
qualityTrain = subset(quality, split == TRUE)
qualityLog <- glm(PoorCare ~ OfficeVisits + Narcotics, data = qualityTrain, family = binomial)
predictTrain <- predict(qualityLog, type = 'response')
summary(qualityLog)
summary(predictTrain)
tapply(predictTrain, qualityTrain$PoorCare,mean)
QualityLog2 = glm(PoorCare ~ StartedOnCombination + ProviderCount, data=qualityTrain, family=binomial)
summary(QualityLog2)
Model = glm(PoorCare ~ StartedOnCombination + ProviderCount, data=qualityTrain, family=binomial)
summary(Model)
table(qualityTrain$PoorCare, predictTrain > 0.5)
install.packages("ROCR")
library(ROCR)
ROCRPred <- prediction(predictTrain, qualityTrain$PoorCare)
ROCRperf <- performance(ROCRPred, "tpr","fpr")
plot(ROCRperf)
plot(ROCRperf, colorize = TRUE)
plot(ROCRperf, colorize = TRUE, print.cutoffs.at= seq(0,1,0.1), text.adj = c(-0.2,1.7))
predictTest = predict(qualityLog, type="response", newdata=qualityTest)
# You can compute the test set AUC by running the following two commands
ROCRpredTest = prediction(predictTest, qualityTest$PoorCare)
auc = as.numeric(performance(ROCRpredTest, "auc")@y.values)
